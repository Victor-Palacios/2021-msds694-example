{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexStringColumns(df, cols):\n",
    "    # variable newdf will be updated several times\n",
    "    newdf = df\n",
    "\n",
    "    for c in cols:\n",
    "        # For each given colum, fits StringIndexerModel.\n",
    "        si = StringIndexer(inputCol=c, outputCol=c + \"-num\")\n",
    "        sm = si.fit(newdf)\n",
    "        # Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\"\n",
    "        # and then drops the original columns.\n",
    "        # and drop the \"-num\" suffix.\n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c + \"-num\", c)\n",
    "    return (newdf, sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColumns(df, cols):\n",
    "    # variable newdf will be updated several times\n",
    "    newdf = df\n",
    "\n",
    "    for c in cols:\n",
    "        # Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\"\n",
    "        # and then drops the original columns.\n",
    "        # and drop the \"-num\" suffix.\n",
    "        newdf = newdf.drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c + \"-num\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFloatSafe(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.getOrCreate()\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = \"../Data/Week4_Discussion_Iris/iris.csv\"\n",
    "test_data = \"../Data/Week4_Discussion_Iris/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_raw = sc.textFile(training_data, 4).map(lambda x: x.split(\",\"))\n",
    "iris_test_raw = sc.textFile(test_data, 4).map(lambda x: x.split(\",\"))\n",
    "\n",
    "irisschema = StructType([\n",
    "    StructField(\"sepal_length\", FloatType(), False),\n",
    "    StructField(\"sepal_width\", FloatType(), False),\n",
    "    StructField(\"petal_length\", FloatType(), False),\n",
    "    StructField(\"petal_width\", FloatType(), False),\n",
    "    StructField(\"class\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIris = ss.createDataFrame(\n",
    "    iris_raw.map(lambda x: (toFloatSafe(x[0]), toFloatSafe(x[1]),\n",
    "                            toFloatSafe(x[2]), toFloatSafe(x[3]), x[4])),\n",
    "    irisschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIris_test = ss.createDataFrame(\n",
    "    iris_test_raw.map(lambda x: (toFloatSafe(x[0]), toFloatSafe(x[1]),\n",
    "                                 toFloatSafe(x[2]), toFloatSafe(x[3]), x[4])),\n",
    "    irisschema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: float (nullable = false)\n",
      " |-- sepal_width: float (nullable = false)\n",
      " |-- petal_length: float (nullable = false)\n",
      " |-- petal_width: float (nullable = false)\n",
      " |-- class: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfIris.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a string indexer and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIrisnumeric, sm = indexStringColumns(dfIris, [\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to apply the same string indexer to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIris_test = sm.transform(dfIris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIris_test = renameColumns(dfIris_test, [\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(outputCol=\"features\", inputCols=dfIris.columns[0:-1])  \n",
    "# except the last col.\n",
    "\n",
    "irispoints = va.transform(dfIrisnumeric).select(\"features\", \"class\")\\\n",
    "                         .withColumnRenamed(\"class\", \"label\").cache()\n",
    "irispoints_test = va.transform(dfIris_test).select(\"features\", \"class\")\\\n",
    "                    .withColumnRenamed(\"class\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and apply Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(maxDepth=1, numTrees=2, maxBins=2, seed=7)\n",
    "rfmodel = rf.fit(irispoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.3347\n"
     ]
    }
   ],
   "source": [
    "rfpredicts = rfmodel.transform(irispoints_test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(rfpredicts)\n",
    "print(\"F1 = %.4f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
